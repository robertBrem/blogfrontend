<div class="col-sm-7" ng-controller="BuildingMicroservicesCtrl">

    <h1>Building Microservices
        <small>Designing fine-grained systems</small>
    </h1>
    <small>by Sam Newman</small>

    <img src="http://akamaicovers.oreilly.com/images/0636920033158/lrg.jpg" alt="Building Microservices cover"/>

    This is my personal review of the book.

    <h2>Microservices
        <small>chapter 1</small>
    </h2>
    This chapter is an introduction in what Microservices are. It does not contain any surprises compared to other
    definition of Microservices. Like the definition of <a href="http://blog.eisele.net/" target="_blank">Markus
    Eisele</a> and others, Sam Newman tells the reader that
    understanding <a href="http://martinfowler.com/bliki/BoundedContext.html" target="_blank">Bounded Context</a> and
    Eric Evans book <a href="http://www.amazon.de/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215"
                       target="_blank">Domain-Driven Design</a> is really important to
    create Microservices, in particular to split the services.<br/>
    A Microservice is small and focused on doing one thing well. Sam Newman mention the <a
        href="http://en.wikipedia.org/wiki/Single_responsibility_principle" target="_blank">Single Responsibility
    Principle</a>
    like I did in <a
        href="http://optimist.engineer/#/posts/Getting_started_with_Microservices_and_Docker__Rob__2015_05_08__08_38_58"
        target="_blank">my post</a> about Microservices. Another important characteristic of Microservices is that
    they
    are autonomous. Therefore it is really important that the services are <a
        href="http://en.wikipedia.org/wiki/Loose_coupling" target="_blank">loosely coupled</a>.<br/><br/>
    Sam Newman then explains some key benefits of Microservices, like:
    <ul>
        <li>Technology Heterogeneity</li>
        <li>
            <a href="http://www.resilientdesign.org/the-resilient-design-principles/" target="_blank">Resilience</a>
        </li>
        <li>Scaling</li>
        <li>Ease of Deployment</li>
        <li>Organizational Alignment</li>
        <li>Composability</li>
        <li>Optimizing for Replaceability</li>
    </ul>
    Important to understand is, that this benefits do not come for free. It requires a lot of work.<br/><br/>
    <blockquote>
        <p>So you should instead think of microservices as a specific approach for SOA in the same way that XP or Scrum
            are specific approaches for Agile software development.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    I really like this definition, it reminds me of this definition.
    <blockquote>
        <p>Microservices = pragmatic SOA</p>
        <footer>Adam Bien</footer>
    </blockquote>
    The underlying concepts of Microservices are not new, but I think it is a lot easier to implement them
    now.<br/><br/>
    Sam Newman give us some other decompositional techniques: Shared libraries and modules.

    <h2>The Evolutionary Architect
        <small>chapter 2</small>
    </h2>
    What is a good architect if you implement Microservices? This chapter covers this question.<br/>
    With Microservices the teams and each software engineer has more power. They can choose the language they like the
    most, the architecture inside the service that fits their needs best and so on. But some parts of each service have
    to
    follow specific rules. The communication between the services should always use the same technology and follow the
    same guidelines.
    <blockquote>
        <p>... think of our role more as town planners than architects for the built environment. The role of the town
            planner should be familiar to any of you who have played SimCity before. A town planner's role is to look at
            a multitude of sources for information, and then attempt to optimize the layout of a city to best suit the
            needs of the citizens today, taking into account future use. The way he influences how the city evolves,
            though, is interesting. He does not say, "build this specific building there"; instead, he zones a city. So
            as in SimCity, you might designate part of your city as an industrial zone, and another part as a
            residential zone. It is then up to other people to decide what exact building get created, but there are
            restrictions: if you want to build a factory, it will need to be in an industrial zone. Rather than worrying
            too much about what happens in one zone, the town planner will instead spend far more time working out how
            people and utilities move from one zone to another.</p>
        <footer>Sam Newman and Erik Doernenburg</footer>
    </blockquote>
    I go one step further and think we need <a href="https://www.youtube.com/watch?v=uk-CF7klLdA" target="_blank">Programmer
    Anarachy</a>. The direction is the same.<br/><br/>
    The decisions are made on three layers.
    <ul>
        <li>Strategic goals</li>
        <li>Architectural principles</li>
        <li>Design and delivery practices</li>
    </ul>
    The architectual principles have the goal to fulfill the strategic goals and the design and delivery practices have
    the goal to fulfill the architectual principles.<br/><br/>
    Sam Newman points out the pros and cons of shared libraries multiple times. If you share code in different services
    your services are coupled tighter. But if you do not use shared code you have to implement the same functionality in
    every service that violates the DRY principle. He also explains the importance of examples. Documentation is good, a
    real example that is running in production is better.

    <h2>How to Model Services
        <small>chapter 3</small>
    </h2>
    A good service is <a
        href="http://en.wikipedia.org/wiki/Loose_coupling" target="_blank">loosely coupled</a> and has <a
        href="http://en.wikipedia.org/wiki/Cohesion_%28computer_science%29" target="_blank">high
    cohesion</a>.<br/>
    There are shared and hidden models. The business have a use case and expect an answer from the system. If you split
    up you services there are always models that are hidden in this service. These
    models do not have to be published by the system. It is important that you do not make CRUD only services, you
    have to target the business use case and distinct between hidden and shared models.<br/><br/>

    <h2>Integration
        <small>chapter 4</small>
    </h2>
    It is really important to keep the options open. Therefore keep your APIs <strong>technology-agnostic</strong>.<br/>
    <strong>Avoid breaking changes</strong>. If you add a field to to an existing data object. The consumers
    should not have to change. Avoid database integration at all costs.<br/>
    <strong>Make your service simple for consumers</strong>. Like I have mentioned in <a
        href="http://optimist.engineer/#/posts/The_first_Java_EE_Microservice__Rob__2015_05_08__17_28_05"
        target="_blank">The first Java EE Microservice</a> a good guideline for creating
    REST services is <a href="https://pages.apigee.com/rs/apigee/images/api-design-ebook-2012-03.pdf" target="_blank">this
    document</a>. REST is not the only suitable technology. Sam Newman compared REST with RPC and both have pros and
    cons, but he strongly consider REST as a good starting point.<br/>
    <strong>Hide internal implementation detail</strong>.<br/><br/>

    The differentiation between Orchestration and Choreography was new for me.
    <blockquote>
        <p>With orchestration, we rely on a central brain to guide and drive the process, much like the conductor in a
            orchestra. With choreography, we inform each part of the system of its job, and let it work out the details,
            like dancers all finding their way and reacting to others around them in a ballet.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    Therefore choreography is most of the time a better fit for Microservices. It is more complex than the orchestration
    approach but with this additional complexity it is really easy to register a new service to another service. We do
    not have to explicit model the connections between the services, it is more like: Please tell me if there is a new
    product in our shop that I can publish this product on our website. Otherwise the first service have to know the web
    service what lead to tighter coupling.<br/>
    Choreography fits perfectly with a asynchronous event-based system. This and the previous discussed properties of
    Microservices reminds me of the <a href="http://www.reactivemanifesto.org/" target="_blank">Reactive
    Manifesto</a>.<br/><br/>
    When it comes to versioning Sam Newman mentioned two links:
    <ul>
        <li><a href="http://martinfowler.com/bliki/TolerantReader.html" target="_blank">Tolerant Reader</a></li>
        <li><a href="http://en.wikipedia.org/wiki/Robustness_principle" target="_blank">Postel's Law</a></li>
    </ul>
    The Postel's Law:
    <blockquote>
        <p>Be conservative in what you do, be liberal in what you accept from others.</p>
        <footer>Jon Postel</footer>
    </blockquote>
    A lot of versioning problems can be solved with <a href="http://semver.org/" target="_blank">Semantic Versioning</a>.
    <blockquote>
        <p>With semantic versioning, each version number is in the form <code>MAJOR.MINOR.PATCH</code>. When the
            <code>MAJOR</code>
            number increments, it means that backward incompatible changes have been made. When <code>MINOR</code>
            increments, new functionality has been added that should be backward compatible. Finally, a change to <code>PATCH</code>
            states that bug fixes have been made to existing functionality.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    Sam Newman describes <strong>UI Fragment Composition</strong>.<br/>
    The straight forward approach for a frontend would be to call service APIs to get the content of the UI. The
    frontend then creates the controls. This can result in tight coupling. For every change always both services have to
    be changed and deployed.
    <strong>UI Fragment Composition</strong> means that the service returns parts of the UI directly. This part can
    then be directly assembled in the frontend. This could result in dedicated backends for frontends:<br/>
    <a href="images/reviews/backends_for_frontends.jpeg" target="_blank">
        <img src="images/reviews/backends_for_frontends_preview.jpg" alt="Backends for frontends"/>
    </a><br/>
    Sam Newman gives this good advice for the question: <strong>Should I build, or should I buy?</strong>
    <blockquote>
        <p>Build if it is unique to what you do, and can be considered a strategic asset; buy if your use of the tool
            isn't that special.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    I did not use an existing blog framework to make my blog because the creation of this blog with AngularJS,
    Bootstrap, Java and so on is a strategic asset for me. :-)<br/>
    Sam Newman gives an example where he integrated a CRM without loosing the control of the system. He masked the CRM
    with own facades.<br/>
    <a href="images/reviews/crm_masking.jpeg" target="_blank">
        <img src="images/reviews/crm_masking_preview.jpg" alt="CRM masking with facades"/>
    </a><br/>
    He also mentioned the <a href="http://martinfowler.com/bliki/StranglerApplication.html" target="_blank">Strangler
    Pattern</a>.

    <h2>Splitting the Monolith
        <small>chapter 5</small>
    </h2>
    The first step to split up a monolith is to identify <strong>seams</strong>. The term seam comes from the book <a
        href="http://www.amazon.de/Working-Effectively-Legacy-Robert-Martin/dp/0131177052" target="_blank">Working
    Effectively with Legacy Code</a> by Michael Feathers. It defines a part of the code that can be changed without
    affecting the rest of the code. Therefore bounded contexts are perfect seams.<br/>
    If you have found some seams you have to check how entangled they are with the rest of the system. Often there is a
    single database that is used from everywhere inside the system. The first step that Sam Newman does is to create
    separate repository layers for each seam.<br/>
    <a href="images/reviews/splitting_up_repositories.jpeg" target="_blank">
        <img src="images/reviews/splitting_up_repositories_preview.jpg" alt="Splitting up repositories"/>
    </a><br/>
    The next step is to map the db tables to the corresponding seams. In most cases this table is used by more than just
    one seam. That can be solved over an API for each seam. The table get just written by one seam and if another seam
    need data from this table it calls the API of this seam and not the db table directly.<br/>
    Some table are used by nearly all seams. If the content of this table is pretty static you have three options:
    <ol>
        <li>duplicate the table for each service</li>
        <li>transform the date of this table into a property file and share it</li>
        <li>extract this part in its own service</li>
    </ol>
    If the content is not static the third option seems to be the only possibility. Another way is to analyze the
    shared content. Sometimes an object that is used by many services are too general and each service just needs one
    part of this object and another service needs just another part of this object. Then you can split up this table
    representation into smaller tables.<br/>
    <br/>
    Now we have split up the monolith in different services with its own repositories and each repository just
    uses its own tables. Therefore we can make an own schema for each repository.<br/>
    The question is now, how do we release this refactoring? Sam Newman recommends to split up the schemas first and in
    a next step to split up the services.<br/>
    <br/>
    The consequences are when we talk about transactions. In a monolith with one schema you can easily use transactions.
    If you split everything up you have to do a lot more to archive a similar behaviour. Most of the time you can life
    with <strong>eventual consistency</strong>.
    <blockquote>
        <p>Rather than using a transactional boundary to ensure that the system is a consistent state when the
            transaction completes, instead we accept that the system will get itself into a consistent state at some
            point in the future.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    Adam Bien often refers to the <a href="http://en.wikipedia.org/wiki/CAP_theorem" target="_blank">CAP theorem</a> and
    explains that you can have two out of these three, but never all three. What often results in the decision: Would I
    have the possibility to scale my system or does the system always have to be consistent. One goal of Microservices
    are the saleability therefore I think if you decide to implement Microservices you should life with eventual
    consistency the most of your time.<br/>
    There is the possibility of <strong>distributed transactions</strong> but they are really hard to implement
    correctly and they can limit scalability.<br/>
    <br/>
    Reporting is always a special field. In a monolithic application it is pretty simple to generate reports. You can
    create one query that gives you all your information back from the database. If you have split up your services it
    isn't that simple anymore. If you have to call the data form the APIs that can be very slow and makes the service
    for the daily business slow too. Sam Newman describes <strong>data pumps</strong> as a first solution. The services
    pushes periodically its data to a central reporting database. The reports can then be produced the same way like
    with a monolith. You have one big db with all the needed data.<br/>
    This system can be extended to <strong>event data pumps</strong>. If you have an event based system (choreography
    over orchestration) then you can send the data that have changed to the reporting database just after the change
    happened.<br/>
    A third approach that is used by Netflix are <strong>backup data pumps</strong>. If you make backups of your data
    anyway you can use this backups for your reporting system. Netflix has open sourced this project too. It is called
    <a href="https://github.com/Netflix/aegisthus" target="_blank">Aegisthus</a>.

    <h2>Deployment
        <small>chapter 6</small>
    </h2>
    From my point of view automation is the most important aspect of Microservices and software engineering at all. A
    good source for further reading and watching is all about <strong>continuous integration</strong>, <strong>continous
    deployment</strong>, <strong>continuous delivery</strong>, <strong>lean</strong>... especially the books from Jez
    Humble <a
        href="http://www.amazon.de/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912/ref=sr_1_1?ie=UTF8&qid=1432291346&sr=8-1&keywords=jez+humble"
        target="_blank">
    Continuous Delivery</a> or <a
        href="http://www.amazon.de/Lean-Enterprise-Performance-Organizations-Innovate/dp/1449368425/ref=sr_1_3?ie=UTF8&qid=1432291346&sr=8-3&keywords=jez+humble"
        target="_blank">Lean Enterprise</a>. There are also some good <a
        href="https://www.youtube.com/results?search_query=jez+humble" target="_blank">Youtube</a> videos from Jez
    Humble as well. Jez Humble ask the following three questions about CI, to check if you really do CI:
    <ol>
        <li>Do you check in to mainline once per day?</li>
        <li>Do you have a suite of tests to validate your changes?</li>
        <li>When the build is broken, is it the #1 priority of the team to fix it?</li>
    </ol>
    If you answer one of these questions with no, you are not doing CI.<br/>
    <br/>
    The goal of CI is that every change in the source code repository triggers a build of the corresponding service and
    its unit tests. It triggers just the pipeline of this service. Therefore you need the possibility to release your
    service independently from each other.<br/>
    When the build and the tests are successful an artifact is created. Then the next stages of the CI
    system are triggered, like static code analysis, integration and acceptance tests, manually usability tests, ... I
    really like the <a href="https://wiki.jenkins-ci.org/display/JENKINS/Build+Pipeline+Plugin" target="_blank">Pipeline
    Plugin</a> from Jenkins. <a href="http://blog.eisele.net/2015/04/continuous-delivery-with-docker.html"
                                target="_blank">This</a> is a interview and demonstration of the plugin from Thomas
    Qvarnstrom and it is really worth to watch.<br/>
    <br/>
    Sam Newman shows a standard release process model for a build pipeline:
    <pre>Compile & fast test -> Slow tests -> user acceptance testing -> performance testing -> production</pre>
    The goal is that we can automate everything and that your deployment environment is as similar to the production
    environment as possible but with fast feedback to the developer. Therefore you need some type of virtualization. Sam
    Newman mentioned technologies like Chef, Puppet, Vagrant, VMWare, VirtualBox and my favorite Docker. That you can
    automate you have to avoid a <strong>configuration drift</strong>. A configuration drift arises if a dev
    or ops is making changes to the environment directly in the program and not in the scripts for the automated set up.
    If you avoid a configuration drift you get <strong>immutable servers</strong>. Immutable servers can easily and fast
    be set up with a singe click and no further configuration.<br/>
    <br/>
    If it comes to the different environments the question arises how to handle environment specific settings like
    usernames and passwords or database connections. It is not a good idea to check them into your source system, but it
    is also not a good idea to always enter them manually every time. A good approach is to create a property file per
    environment or to create a dedicated system for providing configuration. It is important to keep this configuration
    to an absolute minimum.<br/>
    <br/>
    Every service should run in its own host to avoid side effects from the other services. Even better is to divide
    your single service further and for example extract the db out in an own host. If you have hundreds of services it
    is nearly impossible to do that without virtualization. I think the best solution at the moment is <a
        href="http://optimist.engineer/#/posts/Getting_started_with_Microservices_and_Docker__Rob__2015_05_08__08_38_58"
        target="_blank">Docker</a> it is amazing fast and easy compared to other virtualization tools.

    <h2>Testing
        <small>chapter 7</small>
    </h2>
    Sam Newman introduces this chapter with the definition of the different test scopes. He distinguish between:<br/>
    A <strong>Unit Test</strong> tests an isolated small part of the service. These tests are pretty straight forward
    with no magic involved.<br/>
    A <strong>Service Test</strong> tests the service API. It tests the service isolated of the rest of the system,
    without the UI. For the Service Tests we need to stub or mock the other services that get called by this
    service.<br/>
    A <strong>End-to-End Test</strong> tests a user interaction. What happens when the user fill out this form and then
    submits it? Because these tests involve that many moving parts these are very flaky and brittle. It can happen that
    these tests are so flaky that sometimes they are green and sometimes they fail. You should limit these tests to a
    minimum. Just test general journeys and not every story or every boundary condition. Instead of End-to-End Tests try
    to replace them with <strong>Consumer-Driven
    Tests</strong>.<br/>
    <br/>
    With <strong>Consumer-Driven Tests</strong> you test other services if they return the expected value for your
    service. You define a consumer-driven contract (CDC) and test against this contract. The benefit of these tests
    compared with End-to-End Tests are that you have a package of tests. With End-to-End Tests many people and teams are
    involved and if a test fails nobody think he is responsible for this failure. An other advantage is that your can
    reduce the complexity and therefore the moving parts of the test as well. The tests are less flaky and brittle.<br/>
    Sam Newman mentioned <a href="https://github.com/realestate-com-au/pact" target="_blank">Pact</a> and <a
        href="https://github.com/thoughtworks/pacto" target="_blank">Pacto</a> as a testing tool for Consumer-Driven
    Tests.<br/>
    <br/>
    The more you can test with lower complex tests the better. You can archive that when you write a lower complex
    test when a high complex test fails. For example an End-to-End Test fails, you found the solution for the problem
    and then you write a Service Test for this special case. If a Service Test fails and you have found the solution
    write a Unit Test for this special case. If a Unit Test fails you know exactly where the failure happened and you
    just have to understand a small amount of lines instead of tracking down the whole system or service. Another
    important benefit of low complex test is the fast feedback. The faster you get feedback the more present is the
    changed code and you can solve the problem easier.<br/>
    <br/>
    At the end of the build pipeline there a special kinds of tests, the <strong>Performance Tests</strong>. You should
    pay attention to the same properties for performance tests as to the other kind of tests. Try to test
    small parts for performance. If you found a performance issue in a more complex test try to test the cause of the
    problem in a smaller test. It is also important to define boundaries for the performance tests, a performance test
    that never fail has no value.<br/>
    <br/>
    Testing after production is as important as pre production tests. Sam Newman mentioned the <strong>Mean Time To
    Repair</strong> (<strong>MTTR</strong>) and the <strong>Mean Time Between Failures</strong> (<strong>MTBF</strong>).
    And that reducing the MTTR can be significantly more beneficial than to try to lower MTBF with adding more automated
    tests.
    <blockquote>
        <p>If we can spot a problem in production early, and roll back early, we reduce the impact to our costumers. We
            can also use techniques like blue/green deployment, where we deploy a new version of our software and test
            it in situ prior to directing our users to the new version.</p>
        <footer>Sam Newman</footer>
    </blockquote>
    <strong>Blue/green deployment</strong> labeled a deployment that implies that when we deploy our new service
    additionally to the
    current running service. Then we can test our new service in our production environment while the production request
    still use our current service. If our tests on the new service pass we can redirect the production requests to our
    new service and if everything works great terminate the old service.<br/>
    A really cool release technique is <strong>Canary Releasing</strong>. Canary Releasing goes a step further than
    blue/green deployment. You can deploy the new service and redirect a specific amount of production requests to the
    new service. If the the new service runs as expected you can increase the amount of requests for the new service and
    at some point redirect all requests to the new service and terminate the old service. This also allows you to make
    business tests on the services. With the old service 5% of our customers bought something, with the new service 15%
    of our customers bought something. If the result is not satisfying you can redirect the requests to the other
    service.

    <h2>Monitoring
        <small>chapter 8</small>
    </h2>
    When it comes to monitoring Sam Newman differs between:<br/>
    <strong>Single Service, Single Server</strong>, this is the simplest starting point. We have one machine to monitor
    (CPU, RAM, storage, network) and one service with one log file to monitor.<br/>
    <strong>Single Service, Multiple Servers</strong>, in this case we let our service run behind a load balancer. We
    now have multiple machines and multiple services with multiples log files to monitor. But we still can restrict some
    problems, for example if the same failure happens on all services and machines, the possibility is really high that
    the error is in the service and not on the machine. If the failure happened on one machine the probability is
    high that it is just a problem with this single machine and not with the service implementation.<br/>
    The hardest scenario to monitor is <strong>Multiple Services, Multiple Servers</strong>. In this case it is really
    hard to find the cause of a problem, it can be anything.<br/>
    This chapter contains a lot of tool references that help you to consolidate all the log files and allow you to track
    metrics across multiple servers.
    <ul>
        <li><a href="https://www.elastic.co/products/logstash" target="_blank">logstash</a></li>
        <li><a href="https://www.elastic.co/products/kibana" target="_blank">Kibana</a></li>
        <li><a href="http://graphite.wikidot.com/documentation" target="_blank">Graphite</a></li>
        <li><a href="https://dropwizard.github.io/metrics/3.1.0/" target="_blank">Codahale's Metrics library</a></li>
        <li><a href="https://www.nagios.org/" target="_blank">Nagios</a></li>
        <li><a href="http://riemann.io/" target="_blank">Riemann</a></li>
        <li><a href="https://github.com/Netflix/suro" target="_blank">Suro</a></li>
        <li>(<a href="http://twitter.github.io/zipkin/" target="_blank" style="font-style: italic">Zipkin</a>)</li>
    </ul>
    If you have an event based system and a failure happens, it is really hard to find the root of the problem. Sam
    Newman describes the <strong>Correlation IDs</strong> as possible assistance. A Correlation ID is created for every
    new call that is made. This ID get passed to every subsequent call. If now an error happens we can filter our log
    files for the Correlation ID and can step upwards the call history.<br/>
    <br/>
    It is important to consider the audience for the monitoring. Sam Newman gives you three questions you should
    consider for your monitoring decision:
    <ul>
        <li>What they need to know right now?</li>
        <li>What they might want later?</li>
        <li>How they like to consume data?</li>
    </ul>
    Like mentioned in the testing chapter, monitoring is extremely powerful if you have the right focus. Fred George
    mentioned in his talks that he omit acceptance tests, because monitoring with business scope is the best acceptance
    test ever. The company does not care if the response time in the new version is some milliseconds worse than before
    when the profit increased by 25%.

    <br/><br/>

    <h3>to be continued...</h3>

</div>